{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>345.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>345.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.420290</td>\n",
       "      <td>90.159420</td>\n",
       "      <td>69.869565</td>\n",
       "      <td>30.405797</td>\n",
       "      <td>24.643478</td>\n",
       "      <td>38.284058</td>\n",
       "      <td>3.455072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.494322</td>\n",
       "      <td>4.448096</td>\n",
       "      <td>18.347670</td>\n",
       "      <td>19.512309</td>\n",
       "      <td>10.064494</td>\n",
       "      <td>39.254616</td>\n",
       "      <td>3.337835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3           4           5  \\\n",
       "count  345.000000  345.000000  345.000000  345.000000  345.000000  345.000000   \n",
       "mean     0.420290   90.159420   69.869565   30.405797   24.643478   38.284058   \n",
       "std      0.494322    4.448096   18.347670   19.512309   10.064494   39.254616   \n",
       "min      0.000000   65.000000   23.000000    4.000000    5.000000    5.000000   \n",
       "25%      0.000000   87.000000   57.000000   19.000000   19.000000   15.000000   \n",
       "50%      0.000000   90.000000   67.000000   26.000000   23.000000   25.000000   \n",
       "75%      1.000000   93.000000   80.000000   34.000000   27.000000   46.000000   \n",
       "max      1.000000  103.000000  138.000000  155.000000   82.000000  297.000000   \n",
       "\n",
       "                6  \n",
       "count  345.000000  \n",
       "mean     3.455072  \n",
       "std      3.337835  \n",
       "min      0.000000  \n",
       "25%      0.500000  \n",
       "50%      3.000000  \n",
       "75%      6.000000  \n",
       "max     20.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import adaboost\n",
    "import utils\n",
    "import noising\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv(\"DataSet/liver-disorder/bupa.csv\", header=None)\n",
    "Y_index = 0\n",
    "indexes_to_add_feature_noise = [2, 3, 4, 5, 6]\n",
    "max_stds = data[indexes_to_add_feature_noise].describe().ix[\"std\"] * 0.1\n",
    "pPos, pNeg = 0, 0\n",
    "number_of_tries = 10\n",
    "\n",
    "Ts = [10 * i for i in range(1, 21)]\n",
    "Cs = [10 ** i for i in range(-2, 3)]\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TryOuts(indexes_to_add_feature_noise, max_stds, pPos, pNeg):\n",
    "    reload(noising)\n",
    "    reload(utils)\n",
    "\n",
    "    Val_error = np.empty(0)\n",
    "    for p in range(number_of_tries):\n",
    "        # Add noise on features (before scaling)\n",
    "        noisy_data = data\n",
    "        for idx in indexes_to_add_feature_noise:\n",
    "            std = max_stds.ix[idx]\n",
    "            if std > 0:\n",
    "                noisy_data[idx] = noising.addNormalNoise(noisy_data[idx], avg, std)\n",
    "        # Prepare dataset\n",
    "        noisy_data[\"Y\"] = np.where(noisy_data[Y_index] == 0, -1, 1)\n",
    "        noisy_data = noisy_data.drop(Y_index, 1)\n",
    "        noisy_data[noisy_data.drop(\"Y\", 1).columns.values] = scale(noisy_data[noisy_data.drop(\"Y\", 1).columns.values])\n",
    "        # Split train / test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(noisy_data.drop(\"Y\", 1), noisy_data[\"Y\"], test_size=0.33)\n",
    "        # Add noise on labels (On training set ! otherwise doesn't make sense)\n",
    "        y_train = noising.switchLabels(y_train, pPos, pNeg)\n",
    "        # Cross Validate\n",
    "        best_T, cross_validate_accuracy_training = utils.cross_validate_adaboost_T(X_train, y_train, Ts, None, None, 0, False)\n",
    "        # Val. Error\n",
    "        my_adaboost = adaboost.Adaboost(best_T)\n",
    "        my_adaboost.fit(X_train, y_train)\n",
    "        error_val = 1 - my_adaboost.score(X_test, y_test)\n",
    "        Val_error = np.append(Val_error, error_val)\n",
    "        #print \" Round : {0}, Best T : {1}, train error : {2}, val. error : {3}\".format(p + 1, best_T, 1 - cross_validate_accuracy_training, error_val)\n",
    "\n",
    "    print(\"Adaboost Avg. val error : {0}, Std. : {1}\".format(Val_error.mean(), Val_error.std()))\n",
    "\n",
    "    Val_error = np.empty(0)\n",
    "    for p in range(number_of_tries):\n",
    "        # Add noise on features (before scaling)\n",
    "        noisy_data = data\n",
    "        for idx in indexes_to_add_feature_noise:\n",
    "            std = max_stds.ix[idx]\n",
    "            if std > 0:\n",
    "                noisy_data[idx] = noising.addNormalNoise(noisy_data[idx], avg, std)\n",
    "        # Prepare dataset\n",
    "        noisy_data[\"Y\"] = np.where(noisy_data[Y_index] == 0, -1, 1)\n",
    "        noisy_data = noisy_data.drop(Y_index, 1)\n",
    "        noisy_data[noisy_data.drop(\"Y\", 1).columns.values] = scale(noisy_data[noisy_data.drop(\"Y\", 1).columns.values])\n",
    "        # Split train / test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(noisy_data.drop(\"Y\", 1), noisy_data[\"Y\"], test_size=0.33)\n",
    "        # Add noise on labels (On training set ! otherwise doesn't make sense)\n",
    "        y_train = noising.switchLabels(y_train, pPos, pNeg)\n",
    "        # Cross Validate\n",
    "        best_C, best_T, cross_validate_accuracy_training = utils.cross_validate_adaboost_T_C(X_train, y_train, Ts, 2, Cs, 0, False)\n",
    "        # Val. Error\n",
    "        my_adaboost = adaboost.Adaboost(best_T, 2, best_C, 0)\n",
    "        my_adaboost.fit(X_train, y_train)\n",
    "        error_val = 1 - my_adaboost.score(X_test, y_test)\n",
    "        Val_error = np.append(Val_error, error_val)\n",
    "        #print \" Round : {0}, Best T / C : {1}, {2}, train error : {3}, val. error : {4}\".format(p + 1, best_T, best_C, 1 - cross_validate_accuracy_training, error_val)\n",
    "\n",
    "    print(\"L1 regulariazed Adaboost (paper) Avg. val error : {0}, Std. : {1}\".format(Val_error.mean(), Val_error.std()))\n",
    "\n",
    "    Val_error = np.empty(0)\n",
    "    for p in range(number_of_tries):\n",
    "        # Add noise on features (before scaling)\n",
    "        noisy_data = data\n",
    "        for idx in indexes_to_add_feature_noise:\n",
    "            std = max_stds.ix[idx]\n",
    "            if std > 0:\n",
    "                noisy_data[idx] = noising.addNormalNoise(noisy_data[idx], avg, std)\n",
    "        # Prepare dataset\n",
    "        noisy_data[\"Y\"] = np.where(noisy_data[Y_index] == 0, -1, 1)\n",
    "        noisy_data = noisy_data.drop(Y_index, 1)\n",
    "        noisy_data[noisy_data.drop(\"Y\", 1).columns.values] = scale(noisy_data[noisy_data.drop(\"Y\", 1).columns.values])\n",
    "        # Split train / test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(noisy_data.drop(\"Y\", 1), noisy_data[\"Y\"], test_size=0.33)\n",
    "        # Add noise on labels (On training set ! otherwise doesn't make sense)\n",
    "        y_train = noising.switchLabels(y_train, pPos, pNeg)\n",
    "        # Cross Validate\n",
    "        best_C, best_T, cross_validate_accuracy_training = utils.cross_validate_adaboost_T_C(X_train, y_train, Ts, 2, Cs, 1, False)\n",
    "        # Val. Error\n",
    "        my_adaboost = adaboost.Adaboost(best_T, 2, best_C, 1)\n",
    "        my_adaboost.fit(X_train, y_train)\n",
    "        error_val = 1 - my_adaboost.score(X_test, y_test)\n",
    "        Val_error = np.append(Val_error, error_val)\n",
    "        #print \" Round : {0}, Best T : {1}, train error : {2}, val. error : {3}\".format(p + 1, best_T, 1 - cross_validate_accuracy_training, error_val)\n",
    "\n",
    "    print(\"Adaboost v1 Avg. val error : {0}, Std. : {1}\".format(Val_error.mean(), Val_error.std()))\n",
    "\n",
    "    Val_error = np.empty(0)\n",
    "    for p in range(number_of_tries):\n",
    "        # Add noise on features (before scaling)\n",
    "        noisy_data = data\n",
    "        for idx in indexes_to_add_feature_noise:\n",
    "            std = max_stds.ix[idx]\n",
    "            if std > 0:\n",
    "                noisy_data[idx] = noising.addNormalNoise(noisy_data[idx], avg, std)\n",
    "        # Prepare dataset\n",
    "        noisy_data[\"Y\"] = np.where(noisy_data[Y_index] == 0, -1, 1)\n",
    "        noisy_data = noisy_data.drop(Y_index, 1)\n",
    "        noisy_data[noisy_data.drop(\"Y\", 1).columns.values] = scale(noisy_data[noisy_data.drop(\"Y\", 1).columns.values])\n",
    "        # Split train / test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(noisy_data.drop(\"Y\", 1), noisy_data[\"Y\"], test_size=0.33)\n",
    "        # Add noise on labels (On training set ! otherwise doesn't make sense)\n",
    "        y_train = noising.switchLabels(y_train, pPos, pNeg)\n",
    "        # Cross Validate\n",
    "        best_C, best_T, cross_validate_accuracy_training = utils.cross_validate_adaboost_T_C(X_train, y_train, Ts, 3, Cs, 1, False)\n",
    "        # Val. Error\n",
    "        my_adaboost = adaboost.Adaboost(best_T, 3, best_C, 1)\n",
    "        my_adaboost.fit(X_train, y_train)\n",
    "        error_val = 1 - my_adaboost.score(X_test, y_test)\n",
    "        Val_error = np.append(Val_error, error_val)\n",
    "        #print \" Round : {0}, Best T : {1}, train error : {2}, val. error : {3}\".format(p + 1, best_T, 1 - cross_validate_accuracy_training, error_val)\n",
    "\n",
    "    print(\"Adaboost v1 pow 3Avg. val error : {0}, Std. : {1}\".format(Val_error.mean(), Val_error.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level : 0 % of maximum\n",
      "Adaboost Avg. val error : 0.305263157895, Std. : 0.0524558469745\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      "L1 regulariazed Adaboost (paper) Avg. val error : 0.278947368421, Std. : 0.0356964735954\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      "Adaboost v1 Avg. val error : 0.275438596491, Std. : 0.0415534009906\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      "Adaboost v1 pow 3Avg. val error : 0.29649122807, Std. : 0.0397746808728\n",
      "Noise level : 50 % of maximum\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'avg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-638588ff1e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Noise level : 50 % of maximum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnoiseLevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mTryOuts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes_to_add_feature_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_stds\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoiseLevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpPosMax\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoiseLevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpNegMax\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoiseLevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Noise level : 100 % of maximum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-99b5d8c66adf>\u001b[0m in \u001b[0;36mTryOuts\u001b[0;34m(indexes_to_add_feature_noise, max_stds, pPos, pNeg)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_stds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mnoisy_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoising\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddNormalNoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Prepare dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnoisy_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'avg' is not defined"
     ]
    }
   ],
   "source": [
    "pPosMax, pNegMax = 0, 0\n",
    "reload(utils)\n",
    "reload(adaboost)\n",
    "\n",
    "print \"Noise level : 0 % of maximum\"\n",
    "noiseLevel = 0\n",
    "TryOuts(indexes_to_add_feature_noise, max_stds * noiseLevel, pPosMax * noiseLevel, pNegMax * noiseLevel)\n",
    "\n",
    "print \"Noise level : 50 % of maximum\"\n",
    "noiseLevel = 0.5\n",
    "TryOuts(indexes_to_add_feature_noise, max_stds * noiseLevel, pPosMax * noiseLevel, pNegMax * noiseLevel)\n",
    "\n",
    "print \"Noise level : 100 % of maximum\"\n",
    "noiseLevel = 1\n",
    "TryOuts(indexes_to_add_feature_noise, max_stds * noiseLevel, pPosMax * noiseLevel, pNegMax * noiseLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
