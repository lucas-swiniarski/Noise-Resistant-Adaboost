{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.00000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.477778</td>\n",
       "      <td>50.555556</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.017778</td>\n",
       "      <td>1.40000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.960000</td>\n",
       "      <td>12.524444</td>\n",
       "      <td>37.855556</td>\n",
       "      <td>9134.444444</td>\n",
       "      <td>4.495556</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.502304</td>\n",
       "      <td>14.419954</td>\n",
       "      <td>11.940866</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>1.63391</td>\n",
       "      <td>1.039783</td>\n",
       "      <td>0.402241</td>\n",
       "      <td>0.469946</td>\n",
       "      <td>0.364464</td>\n",
       "      <td>0.341839</td>\n",
       "      <td>...</td>\n",
       "      <td>4.558257</td>\n",
       "      <td>3.171159</td>\n",
       "      <td>9.738792</td>\n",
       "      <td>3739.108862</td>\n",
       "      <td>1.080461</td>\n",
       "      <td>0.487548</td>\n",
       "      <td>0.465542</td>\n",
       "      <td>0.329377</td>\n",
       "      <td>0.410383</td>\n",
       "      <td>0.418069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3800.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>9.925000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>6725.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>8600.000000</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.750000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.025000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10475.000000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>1.025000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1           2          3         4          5   \\\n",
       "count  90.000000  90.000000   90.000000  90.000000  90.00000  90.000000   \n",
       "mean    0.477778  50.555556   77.000000   1.017778   1.40000   0.444444   \n",
       "std     0.502304  14.419954   11.940866   0.006186   1.63391   1.039783   \n",
       "min     0.000000   6.000000   50.000000   1.005000   0.00000   0.000000   \n",
       "25%     0.000000  42.250000   70.000000   1.010000   0.00000   0.000000   \n",
       "50%     0.000000  52.000000   80.000000   1.020000   0.00000   0.000000   \n",
       "75%     1.000000  59.750000   80.000000   1.025000   3.00000   0.000000   \n",
       "max     1.000000  83.000000  110.000000   1.025000   4.00000   5.000000   \n",
       "\n",
       "              6          7          8          9     ...             14  \\\n",
       "count  90.000000  90.000000  90.000000  90.000000    ...      90.000000   \n",
       "mean    0.200000   0.322222   0.155556   0.133333    ...       4.960000   \n",
       "std     0.402241   0.469946   0.364464   0.341839    ...       4.558257   \n",
       "min     0.000000   0.000000   0.000000   0.000000    ...       2.500000   \n",
       "25%     0.000000   0.000000   0.000000   0.000000    ...       3.900000   \n",
       "50%     0.000000   0.000000   0.000000   0.000000    ...       4.600000   \n",
       "75%     0.000000   1.000000   0.000000   0.000000    ...       5.000000   \n",
       "max     1.000000   1.000000   1.000000   1.000000    ...      47.000000   \n",
       "\n",
       "              15         16            17         18         19         20  \\\n",
       "count  90.000000  90.000000     90.000000  90.000000  90.000000  90.000000   \n",
       "mean   12.524444  37.855556   9134.444444   4.495556   0.377778   0.311111   \n",
       "std     3.171159   9.738792   3739.108862   1.080461   0.487548   0.465542   \n",
       "min     3.100000   9.000000   3800.000000   2.100000   0.000000   0.000000   \n",
       "25%     9.925000  30.000000   6725.000000   3.700000   0.000000   0.000000   \n",
       "50%    13.200000  41.000000   8600.000000   4.550000   0.000000   0.000000   \n",
       "75%    15.000000  45.000000  10475.000000   5.200000   1.000000   1.000000   \n",
       "max    17.300000  52.000000  26400.000000   8.000000   1.000000   1.000000   \n",
       "\n",
       "              21         22         23  \n",
       "count  90.000000  90.000000  90.000000  \n",
       "mean    0.122222   0.211111   0.222222  \n",
       "std     0.329377   0.410383   0.418069  \n",
       "min     0.000000   0.000000   0.000000  \n",
       "25%     0.000000   0.000000   0.000000  \n",
       "50%     0.000000   0.000000   0.000000  \n",
       "75%     0.000000   0.000000   0.000000  \n",
       "max     1.000000   1.000000   1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import adaboost\n",
    "import utils\n",
    "import noising\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv(\"DataSet/Chronic_Kidney_Disease/chronic_kidney.csv\", header=None)\n",
    "Y_index = 1\n",
    "indexes_to_add_feature_noise = [3, 4, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "max_stds = data[indexes_to_add_feature_noise].describe().ix[\"std\"]\n",
    "pPos, pNeg = 0, 0\n",
    "number_of_tries = 10\n",
    "\n",
    "Ts = [10 * i for i in range(1, 21)]\n",
    "Cs = [10 ** i for i in range(-2, 3)]\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def TryOuts(indexes_to_add_feature_noise, max_stds, pPos, pNeg):\n",
    "    reload(noising)\n",
    "    reload(utils)\n",
    "\n",
    "    Val_error = np.empty(0)\n",
    "    for p in range(number_of_tries):\n",
    "        # Add noise on features (before scaling)\n",
    "        noisy_data = data\n",
    "        for idx in indexes_to_add_feature_noise:\n",
    "            std = max_stds.ix[idx]\n",
    "            if std > 0:\n",
    "                noisy_data[idx] = noising.addNormalNoise(noisy_data[idx], avg, std)\n",
    "        # Prepare dataset\n",
    "        noisy_data[\"Y\"] = np.where(noisy_data[Y_index] == 0, -1, 1)\n",
    "        noisy_data = noisy_data.drop(Y_index, 1)\n",
    "        noisy_data[noisy_data.drop(\"Y\", 1).columns.values] = scale(noisy_data[noisy_data.drop(\"Y\", 1).columns.values])\n",
    "        # Split train / test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(noisy_data.drop(\"Y\", 1), noisy_data[\"Y\"], test_size=0.33)\n",
    "        # Add noise on labels (On training set ! otherwise doesn't make sense)\n",
    "        y_train = noising.switchLabels(y_train, pPos, pNeg)\n",
    "        # Cross Validate\n",
    "        best_T, cross_validate_accuracy_training = utils.cross_validate_adaboost_T(X_train, y_train, Ts, None, None, 0, False)\n",
    "        # Val. Error\n",
    "        my_adaboost = adaboost.Adaboost(best_T)\n",
    "        my_adaboost.fit(X_train, y_train)\n",
    "        error_val = 1 - my_adaboost.score(X_test, y_test)\n",
    "        Val_error = np.append(Val_error, error_val)\n",
    "        #print \" Round : {0}, Best T : {1}, train error : {2}, val. error : {3}\".format(p + 1, best_T, 1 - cross_validate_accuracy_training, error_val)\n",
    "\n",
    "    print(\"Adaboost Avg. val error : {0}, Std. : {1}\".format(Val_error.mean(), Val_error.std()))\n",
    "\n",
    "    Val_error = np.empty(0)\n",
    "    for p in range(number_of_tries):\n",
    "        # Add noise on features (before scaling)\n",
    "        noisy_data = data\n",
    "        for idx in indexes_to_add_feature_noise:\n",
    "            std = max_stds.ix[idx]\n",
    "            if std > 0:\n",
    "                noisy_data[idx] = noising.addNormalNoise(noisy_data[idx], avg, std)\n",
    "        # Prepare dataset\n",
    "        noisy_data[\"Y\"] = np.where(noisy_data[Y_index] == 0, -1, 1)\n",
    "        noisy_data = noisy_data.drop(Y_index, 1)\n",
    "        noisy_data[noisy_data.drop(\"Y\", 1).columns.values] = scale(noisy_data[noisy_data.drop(\"Y\", 1).columns.values])\n",
    "        # Split train / test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(noisy_data.drop(\"Y\", 1), noisy_data[\"Y\"], test_size=0.33)\n",
    "        # Add noise on labels (On training set ! otherwise doesn't make sense)\n",
    "        y_train = noising.switchLabels(y_train, pPos, pNeg)\n",
    "        # Cross Validate\n",
    "        best_C, best_T, cross_validate_accuracy_training = utils.cross_validate_adaboost_T_C(X_train, y_train, Ts, 2, Cs, 0, False)\n",
    "        # Val. Error\n",
    "        my_adaboost = adaboost.Adaboost(best_T, 2, best_C, 0)\n",
    "        my_adaboost.fit(X_train, y_train)\n",
    "        error_val = 1 - my_adaboost.score(X_test, y_test)\n",
    "        Val_error = np.append(Val_error, error_val)\n",
    "        #print \" Round : {0}, Best T / C : {1}, {2}, train error : {3}, val. error : {4}\".format(p + 1, best_T, best_C, 1 - cross_validate_accuracy_training, error_val)\n",
    "\n",
    "    print(\"L1 regulariazed Adaboost (paper) Avg. val error : {0}, Std. : {1}\".format(Val_error.mean(), Val_error.std()))\n",
    "\n",
    "    Val_error = np.empty(0)\n",
    "    for p in range(number_of_tries):\n",
    "        # Add noise on features (before scaling)\n",
    "        noisy_data = data\n",
    "        for idx in indexes_to_add_feature_noise:\n",
    "            std = max_stds.ix[idx]\n",
    "            if std > 0:\n",
    "                noisy_data[idx] = noising.addNormalNoise(noisy_data[idx], avg, std)\n",
    "        # Prepare dataset\n",
    "        noisy_data[\"Y\"] = np.where(noisy_data[Y_index] == 0, -1, 1)\n",
    "        noisy_data = noisy_data.drop(Y_index, 1)\n",
    "        noisy_data[noisy_data.drop(\"Y\", 1).columns.values] = scale(noisy_data[noisy_data.drop(\"Y\", 1).columns.values])\n",
    "        # Split train / test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(noisy_data.drop(\"Y\", 1), noisy_data[\"Y\"], test_size=0.33)\n",
    "        # Add noise on labels (On training set ! otherwise doesn't make sense)\n",
    "        y_train = noising.switchLabels(y_train, pPos, pNeg)\n",
    "        # Cross Validate\n",
    "        best_C, best_T, cross_validate_accuracy_training = utils.cross_validate_adaboost_T_C(X_train, y_train, Ts, 2, Cs, 1, False)\n",
    "        # Val. Error\n",
    "        my_adaboost = adaboost.Adaboost(best_T, 2, best_C, 1)\n",
    "        my_adaboost.fit(X_train, y_train)\n",
    "        error_val = 1 - my_adaboost.score(X_test, y_test)\n",
    "        Val_error = np.append(Val_error, error_val)\n",
    "        #print \" Round : {0}, Best T : {1}, train error : {2}, val. error : {3}\".format(p + 1, best_T, 1 - cross_validate_accuracy_training, error_val)\n",
    "\n",
    "    print(\"Adaboost v1 Avg. val error : {0}, Std. : {1}\".format(Val_error.mean(), Val_error.std()))\n",
    "\n",
    "    Val_error = np.empty(0)\n",
    "    for p in range(number_of_tries):\n",
    "        # Add noise on features (before scaling)\n",
    "        noisy_data = data\n",
    "        for idx in indexes_to_add_feature_noise:\n",
    "            std = max_stds.ix[idx]\n",
    "            if std > 0:\n",
    "                noisy_data[idx] = noising.addNormalNoise(noisy_data[idx], avg, std)\n",
    "        # Prepare dataset\n",
    "        noisy_data[\"Y\"] = np.where(noisy_data[Y_index] == 0, -1, 1)\n",
    "        noisy_data = noisy_data.drop(Y_index, 1)\n",
    "        noisy_data[noisy_data.drop(\"Y\", 1).columns.values] = scale(noisy_data[noisy_data.drop(\"Y\", 1).columns.values])\n",
    "        # Split train / test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(noisy_data.drop(\"Y\", 1), noisy_data[\"Y\"], test_size=0.33)\n",
    "        # Add noise on labels (On training set ! otherwise doesn't make sense)\n",
    "        y_train = noising.switchLabels(y_train, pPos, pNeg)\n",
    "        # Cross Validate\n",
    "        best_C, best_T, cross_validate_accuracy_training = utils.cross_validate_adaboost_T_C(X_train, y_train, Ts, 3, Cs, 1, False)\n",
    "        # Val. Error\n",
    "        my_adaboost = adaboost.Adaboost(best_T, 3, best_C, 1)\n",
    "        my_adaboost.fit(X_train, y_train)\n",
    "        error_val = 1 - my_adaboost.score(X_test, y_test)\n",
    "        Val_error = np.append(Val_error, error_val)\n",
    "        #print \" Round : {0}, Best T : {1}, train error : {2}, val. error : {3}\".format(p + 1, best_T, 1 - cross_validate_accuracy_training, error_val)\n",
    "\n",
    "    print(\"Adaboost v1 pow 3Avg. val error : {0}, Std. : {1}\".format(Val_error.mean(), Val_error.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise level : 0 % of maximum\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      "Adaboost Avg. val error : 0.0, Std. : 0.0\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      "L1 regulariazed Adaboost (paper) Avg. val error : 0.0, Std. : 0.0\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      "Adaboost v1 Avg. val error : 0.0, Std. : 0.0\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      "Adaboost v1 pow 3Avg. val error : 0.0, Std. : 0.0\n",
      "Noise level : 50 % of maximum\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      "Adaboost Avg. val error : 0.0, Std. : 0.0\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      "L1 regulariazed Adaboost (paper) Avg. val error : 0.0, Std. : 0.0\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      "Adaboost v1 Avg. val error : 0.0, Std. : 0.0\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      "Adaboost v1 pow 3Avg. val error : 0.0, Std. : 0.0\n",
      "Noise level : 100 % of maximum\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      " The cross validation is not effective, best T found on border\n",
      "Adaboost Avg. val error : 0.0, Std. : 0.0\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      "L1 regulariazed Adaboost (paper) Avg. val error : 0.0, Std. : 0.0\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      "Adaboost v1 Avg. val error : 0.0, Std. : 0.0\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      " The cross validation is not effective, best C or T found on border\n",
      "Adaboost v1 pow 3Avg. val error : 0.0, Std. : 0.0\n"
     ]
    }
   ],
   "source": [
    "pPosMax, pNegMax = 0, 0\n",
    "reload(utils)\n",
    "reload(adaboost)\n",
    "\n",
    "print \"Noise level : 0 % of maximum\"\n",
    "noiseLevel = 0\n",
    "TryOuts(indexes_to_add_feature_noise, max_stds * noiseLevel, pPosMax * noiseLevel, pNegMax * noiseLevel)\n",
    "\n",
    "print \"Noise level : 50 % of maximum\"\n",
    "noiseLevel = 0.5\n",
    "TryOuts(indexes_to_add_feature_noise, max_stds * noiseLevel, pPosMax * noiseLevel, pNegMax * noiseLevel)\n",
    "\n",
    "print \"Noise level : 100 % of maximum\"\n",
    "noiseLevel = 1\n",
    "TryOuts(indexes_to_add_feature_noise, max_stds * noiseLevel, pPosMax * noiseLevel, pNegMax * noiseLevel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
